{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regresión:\n",
      "MSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R2: 0.4827\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Cargar data_descartada desde el archivo CSV\n",
    "data_descartada = pd.read_csv('data_descartada.csv')\n",
    "\n",
    "# Variables independientes (X) y variable dependiente (y)\n",
    "X = data_descartada.drop(columns=['NRO TOTAL MICROCREDITO', 'NRO DEPOSITOS', 'NRO GIROS ENVIADOS', 'NRO GIROS RECIBIDOS'])\n",
    "y = data_descartada['NRO TOTAL MICROCREDITO']\n",
    "\n",
    "# Imputar los valores faltantes\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Modelo de Gradient Boosting\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Validación cruzada y predicciones\n",
    "cv_folds = 3  # Cambia el número de pliegues aquí\n",
    "y_pred_cv = cross_val_predict(gb_model, X_std, y, cv=cv_folds, n_jobs=-1)\n",
    "\n",
    "# Funciones para calcular y mostrar métricas\n",
    "def calculate_regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    metrics = {'MSE': mse, 'MAE': mae, 'R2': r2}\n",
    "    return metrics\n",
    "\n",
    "def display_regression_metrics(metrics_dict):\n",
    "    print(\"Métricas de Regresión:\")\n",
    "    for metric, value in metrics_dict.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Calcular y mostrar métricas de regresión\n",
    "metrics_cv = calculate_regression_metrics(y, y_pred_cv)\n",
    "display_regression_metrics(metrics_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando los resultados obtenidos en el modelo de Gradient Boosting utilizando validación cruzada con los resultados anteriores, se pueden observar algunos cambios en el desempeño del modelo. A continuación, describiré los cambios y proporcionaré posibles razones para estos cambios:\n",
    "\n",
    "1. Resultados Anteriores (Entrenamiento y Prueba):\n",
    "\n",
    "- Mean Squared Error (MSE): 971.97\n",
    "- R-squared (R2): 0.9989\n",
    "\n",
    "2. Resultados con Validación Cruzada:\n",
    "\n",
    "- Mean Squared Error (MSE): 0.0000\n",
    "- Mean Absolute Error (MAE): 0.0000\n",
    "- R-squared (R2): 0.4827\n",
    "\n",
    "\n",
    "Cambios en el Desempeño:\n",
    "\n",
    "- MSE y MAE:\n",
    "    - Los resultados anteriores mostraban un MSE de 971.97 en el conjunto de prueba, lo que indicaba un nivel razonable de ajuste y error moderado.\n",
    "    - En los resultados de validación cruzada, el MSE y MAE son muy cercanos a cero, lo que sugiere un ajuste perfecto en la muestra utilizada.\n",
    "- R2:\n",
    "    - El R2 anterior indicaba que aproximadamente el 99.89% de la variabilidad de los datos se explicaba por el modelo.\n",
    "    - El R2 en los resultados de validación cruzada es más bajo, alrededor del 48.27%, lo que sugiere que el modelo explica menos variabilidad en los datos.\n",
    "\n",
    "Razones Posibles:\n",
    "\n",
    "- Sobreajuste: Los resultados de validación cruzada muestran un ajuste perfecto en la muestra utilizada. Esto podría deberse a un posible sobreajuste del modelo a los datos de entrenamiento. Es decir, el modelo puede haber aprendido los datos de entrenamiento tan específicamente que no generaliza bien a nuevos datos.\n",
    "\n",
    "- Tamaño de la Muestra: La muestra utilizada en la validación cruzada podría ser pequeña en relación con la complejidad del modelo. Un tamaño de muestra pequeño podría llevar a un ajuste excesivo y a resultados poco realistas.\n",
    "\n",
    "- Representatividad de los Datos: Los datos utilizados en la validación cruzada podrían no ser completamente representativos de la población general. Si los datos no son una muestra adecuada, los resultados de validación cruzada pueden ser engañosos.\n",
    "\n",
    "- Selección de Características: La selección de características puede tener un impacto significativo en el desempeño del modelo. Si se utilizan características irrelevantes o se omiten características importantes, los resultados pueden variar drásticamente.\n",
    "\n",
    "En general, los resultados de validación cruzada muestran un desempeño extremadamente optimista y poco realista del modelo. Es importante considerar estos resultados en el contexto de las razones mencionadas anteriormente. Para obtener una evaluación más precisa del rendimiento del modelo, se recomienda utilizar un conjunto de datos más grande y aplicar técnicas de validación cruzada más robustas, como la estratificación y el aumento del número de pliegues, para evitar conclusiones incorrectas basadas en un ajuste perfecto en una muestra pequeña."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizaremos la técnica de regresión Ridge para aplicar regularización y asi superar el sobreajuste que tenemos como problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/extmath.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de Regresión con Regularización Ridge:\n",
      "MSE: 0.0000\n",
      "MAE: 0.0000\n",
      "R2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "DATA_PATH = 'Inclusion_Financiera.csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Cargar data_descartada desde el archivo CSV\n",
    "data_descartada = pd.read_csv('data_descartada.csv')\n",
    "\n",
    "# Variables independientes (X) y variable dependiente (y)\n",
    "X = data_descartada.drop(columns=['NRO TOTAL MICROCREDITO', 'NRO DEPOSITOS', 'NRO GIROS ENVIADOS', 'NRO GIROS RECIBIDOS'])\n",
    "y = data_descartada['NRO TOTAL MICROCREDITO']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear un imputador SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Imputar los valores faltantes en los datos de entrenamiento y prueba\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train_imputed)\n",
    "X_test_std = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Entrenar el modelo con regularización Ridge\n",
    "ridge_model = RidgeCV(alphas=[0.01, 0.1, 1.0, 10.0], cv=5)\n",
    "ridge_model.fit(X_train_std, y_train)\n",
    "\n",
    "# Realizar predicciones en los datos de prueba\n",
    "y_pred = ridge_model.predict(X_test_std)\n",
    "\n",
    "# Calcular y mostrar métricas de regresión\n",
    "metrics = {\n",
    "    'MSE': mean_squared_error(y_test, y_pred),\n",
    "    'MAE': mean_absolute_error(y_test, y_pred),\n",
    "    'R2': r2_score(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Mostrar métricas\n",
    "print(\"Métricas de Regresión con Regularización Ridge:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos indican que el modelo de regresión Ridge con regularización ha logrado ajustarse muy bien a los datos de prueba. Las métricas de regresión (MSE, MAE, R2) son excelentes y en particular el coeficiente de determinación (R2) es 1.0000, lo que significa que el modelo está explicando la variabilidad de los datos de manera perfecta.\n",
    "\n",
    "Este resultado es bastante sorprendente y poco común. En la mayoría de los casos, un R2 de 1.0000 indica un posible problema, como sobreajuste o errores en los datos. Es importante considerar que este resultado puede ser debido a la naturaleza particular de los datos, la cantidad de características y la forma en que se han procesado y utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
